{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('tweets.queries.tsv', sep='\\t')\n",
    "#df['tweet_lables'] = 'No Labels'\n",
    "#df.to_csv('tweets.queries.tsv', sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data/Random Samples/5k_sample.tsv', sep='\\t', header=0)\n",
    "# df.to_csv('data/Random Samples/5k_sample.csv', index = False)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_time_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_tr = pd.read_csv('data/train/tweets.queries.tsv', sep='\\t', header=0, index_col=0)\n",
    "tweets_tr.sort_index(inplace=True)\n",
    "\n",
    "tweets_dev = pd.read_csv('data/dev/tweets.queries.tsv', sep='\\t', header=0, index_col=0)\n",
    "tweets_dev.sort_index(inplace=True)\n",
    "\n",
    "start_time1 = time.time()\n",
    "tweets_te = pd.read_csv('data/test_tweets.queries.tsv', sep='\\t', header=0, index_col=0)\n",
    "tweets_te.sort_index(inplace=True)\n",
    "execution_time_list.append(time.time() - start_time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_tr = tweets_tr.drop_duplicates(\"tweet_content\" , keep='first')\n",
    "tweets_dev = tweets_dev.drop_duplicates(\"tweet_content\" , keep='first')\n",
    "#tweets_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vclaim</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122 detainees released from confinement at Gua...</td>\n",
       "      <td>Did 122 Prisoners Released from Guantanamo by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70 per cent of the persons arrested during pro...</td>\n",
       "      <td>70% of Arrested Charlotte Protesters Are Out-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A \"Trump and Obama by the Numbers\" meme recoun...</td>\n",
       "      <td>Does This Meme Accurately Show ‘Trump and Obam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A \"large-scale killing\" of white farmers is ta...</td>\n",
       "      <td>Is a ‘Large-Scale Killing’ of White Farmers Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A \"law to separate families\" was enacted prior...</td>\n",
       "      <td>Was the ‘Law to Separate Families’ Passed in 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>“Slime,” a do-it-yourself gooey craft project ...</td>\n",
       "      <td>Does the “Slime” Craze Bring Serious Health Ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>“Sun tea” (tea brewed by being left to steep i...</td>\n",
       "      <td>Bacteria in Sun Tea Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>“The Real Deal,” words of wisdom about gas, ge...</td>\n",
       "      <td>Red Thomas ‘Real Deal’ Letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>“Valentine’s Day” worm.</td>\n",
       "      <td>Valentine’s Day Worm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>“WTC Survivor.”</td>\n",
       "      <td>WTC Survivor Virus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  vclaim  \\\n",
       "0      122 detainees released from confinement at Gua...   \n",
       "1      70 per cent of the persons arrested during pro...   \n",
       "2      A \"Trump and Obama by the Numbers\" meme recoun...   \n",
       "3      A \"large-scale killing\" of white farmers is ta...   \n",
       "4      A \"law to separate families\" was enacted prior...   \n",
       "...                                                  ...   \n",
       "10370  “Slime,” a do-it-yourself gooey craft project ...   \n",
       "10371  “Sun tea” (tea brewed by being left to steep i...   \n",
       "10372  “The Real Deal,” words of wisdom about gas, ge...   \n",
       "10373                            “Valentine’s Day” worm.   \n",
       "10374                                    “WTC Survivor.”   \n",
       "\n",
       "                                                   title  \n",
       "0      Did 122 Prisoners Released from Guantanamo by ...  \n",
       "1      70% of Arrested Charlotte Protesters Are Out-o...  \n",
       "2      Does This Meme Accurately Show ‘Trump and Obam...  \n",
       "3      Is a ‘Large-Scale Killing’ of White Farmers Un...  \n",
       "4      Was the ‘Law to Separate Families’ Passed in 1...  \n",
       "...                                                  ...  \n",
       "10370  Does the “Slime” Craze Bring Serious Health Ri...  \n",
       "10371                           Bacteria in Sun Tea Risk  \n",
       "10372                      Red Thomas ‘Real Deal’ Letter  \n",
       "10373                               Valentine’s Day Worm  \n",
       "10374                                 WTC Survivor Virus  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclaims = pd.read_csv('data/verified_claims.docs.tsv', sep='\\t', header=0, index_col=0)\n",
    "\n",
    "#Execution Time\n",
    "#vclaims = pd.read_csv('data/Random Samples/1k_sample.tsv', sep='\\t', header=0, index_col=0)\n",
    "#vclaims = pd.read_csv('data/Random Samples/5k_sample.tsv', sep='\\t', header=0, index_col=0)\n",
    "#vclaims = pd.read_csv('data/Random Samples/10k_sample.tsv', sep='\\t', header=0, index_col=0)\n",
    "\n",
    "vclaims.sort_index(inplace=True)\n",
    "vclaims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vclaims_tr = vclaims.drop_duplicates(\"vclaim\" , keep='first')\n",
    "vclaims_tr = vclaims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vclaim</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122 detainees released from confinement at Gua...</td>\n",
       "      <td>Did 122 Prisoners Released from Guantanamo by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70 per cent of the persons arrested during pro...</td>\n",
       "      <td>70% of Arrested Charlotte Protesters Are Out-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A \"Trump and Obama by the Numbers\" meme recoun...</td>\n",
       "      <td>Does This Meme Accurately Show ‘Trump and Obam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A \"large-scale killing\" of white farmers is ta...</td>\n",
       "      <td>Is a ‘Large-Scale Killing’ of White Farmers Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A \"law to separate families\" was enacted prior...</td>\n",
       "      <td>Was the ‘Law to Separate Families’ Passed in 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>“Slime,” a do-it-yourself gooey craft project ...</td>\n",
       "      <td>Does the “Slime” Craze Bring Serious Health Ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>“Sun tea” (tea brewed by being left to steep i...</td>\n",
       "      <td>Bacteria in Sun Tea Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>“The Real Deal,” words of wisdom about gas, ge...</td>\n",
       "      <td>Red Thomas ‘Real Deal’ Letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>“Valentine’s Day” worm.</td>\n",
       "      <td>Valentine’s Day Worm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>“WTC Survivor.”</td>\n",
       "      <td>WTC Survivor Virus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  vclaim  \\\n",
       "0      122 detainees released from confinement at Gua...   \n",
       "1      70 per cent of the persons arrested during pro...   \n",
       "2      A \"Trump and Obama by the Numbers\" meme recoun...   \n",
       "3      A \"large-scale killing\" of white farmers is ta...   \n",
       "4      A \"law to separate families\" was enacted prior...   \n",
       "...                                                  ...   \n",
       "10370  “Slime,” a do-it-yourself gooey craft project ...   \n",
       "10371  “Sun tea” (tea brewed by being left to steep i...   \n",
       "10372  “The Real Deal,” words of wisdom about gas, ge...   \n",
       "10373                            “Valentine’s Day” worm.   \n",
       "10374                                    “WTC Survivor.”   \n",
       "\n",
       "                                                   title  \n",
       "0      Did 122 Prisoners Released from Guantanamo by ...  \n",
       "1      70% of Arrested Charlotte Protesters Are Out-o...  \n",
       "2      Does This Meme Accurately Show ‘Trump and Obam...  \n",
       "3      Is a ‘Large-Scale Killing’ of White Farmers Un...  \n",
       "4      Was the ‘Law to Separate Families’ Passed in 1...  \n",
       "...                                                  ...  \n",
       "10370  Does the “Slime” Craze Bring Serious Health Ri...  \n",
       "10371                           Bacteria in Sun Tea Risk  \n",
       "10372                      Red Thomas ‘Real Deal’ Letter  \n",
       "10373                               Valentine’s Day Worm  \n",
       "10374                                 WTC Survivor Virus  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclaims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vclaim</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122 detainees released from confinement at Gua...</td>\n",
       "      <td>Did 122 Prisoners Released from Guantanamo by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70 per cent of the persons arrested during pro...</td>\n",
       "      <td>70% of Arrested Charlotte Protesters Are Out-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A \"Trump and Obama by the Numbers\" meme recoun...</td>\n",
       "      <td>Does This Meme Accurately Show ‘Trump and Obam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A \"large-scale killing\" of white farmers is ta...</td>\n",
       "      <td>Is a ‘Large-Scale Killing’ of White Farmers Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A \"law to separate families\" was enacted prior...</td>\n",
       "      <td>Was the ‘Law to Separate Families’ Passed in 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>“Slime,” a do-it-yourself gooey craft project ...</td>\n",
       "      <td>Does the “Slime” Craze Bring Serious Health Ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>“Sun tea” (tea brewed by being left to steep i...</td>\n",
       "      <td>Bacteria in Sun Tea Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>“The Real Deal,” words of wisdom about gas, ge...</td>\n",
       "      <td>Red Thomas ‘Real Deal’ Letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>“Valentine’s Day” worm.</td>\n",
       "      <td>Valentine’s Day Worm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>“WTC Survivor.”</td>\n",
       "      <td>WTC Survivor Virus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  vclaim  \\\n",
       "0      122 detainees released from confinement at Gua...   \n",
       "1      70 per cent of the persons arrested during pro...   \n",
       "2      A \"Trump and Obama by the Numbers\" meme recoun...   \n",
       "3      A \"large-scale killing\" of white farmers is ta...   \n",
       "4      A \"law to separate families\" was enacted prior...   \n",
       "...                                                  ...   \n",
       "10370  “Slime,” a do-it-yourself gooey craft project ...   \n",
       "10371  “Sun tea” (tea brewed by being left to steep i...   \n",
       "10372  “The Real Deal,” words of wisdom about gas, ge...   \n",
       "10373                            “Valentine’s Day” worm.   \n",
       "10374                                    “WTC Survivor.”   \n",
       "\n",
       "                                                   title  \n",
       "0      Did 122 Prisoners Released from Guantanamo by ...  \n",
       "1      70% of Arrested Charlotte Protesters Are Out-o...  \n",
       "2      Does This Meme Accurately Show ‘Trump and Obam...  \n",
       "3      Is a ‘Large-Scale Killing’ of White Farmers Un...  \n",
       "4      Was the ‘Law to Separate Families’ Passed in 1...  \n",
       "...                                                  ...  \n",
       "10370  Does the “Slime” Craze Bring Serious Health Ri...  \n",
       "10371                           Bacteria in Sun Tea Risk  \n",
       "10372                      Red Thomas ‘Real Deal’ Letter  \n",
       "10373                               Valentine’s Day Worm  \n",
       "10374                                 WTC Survivor Virus  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vclaims_test = pd.read_csv('data/test/verified_claims.docs.tsv', sep='\\t', header=0, index_col=0) \n",
    "\n",
    "#Execution Time\n",
    "#vclaims_test = pd.read_csv('data/Random Samples/1k_sample.tsv', sep='\\t', header=0, index_col=0)\n",
    "#vclaims_test = pd.read_csv('data/Random Samples/5k_sample.tsv', sep='\\t', header=0, index_col=0)\n",
    "#vclaims_test = pd.read_csv('data/Random Samples/10k_sample.tsv', sep='\\t', header=0, index_col=0)\n",
    "\n",
    "\n",
    "vclaims_test.sort_index(inplace=True)\n",
    "#vclaims_test = vclaims_test.drop_duplicates(\"vclaim\" , keep='first')\n",
    "vclaims_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_tr = pd.read_csv('data/train/tweet-vclaim-pairs.qrels', sep='\\t', \n",
    "                       header=None, names=['tweet_id', '0', 'vclaim_id', 'relevance'])\n",
    "\n",
    "qrels_dev = pd.read_csv('data/dev/tweet-vclaim-pairs.qrels', sep='\\t', \n",
    "                       header=None, names=['tweet_id', '0', 'vclaim_id', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>0</th>\n",
       "      <th>vclaim_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>994</td>\n",
       "      <td>0</td>\n",
       "      <td>652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>998</td>\n",
       "      <td>0</td>\n",
       "      <td>539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id  0  vclaim_id  relevance\n",
       "0           1  0        394          1\n",
       "1           2  0        670          1\n",
       "2           3  0        670          1\n",
       "3           4  0        141          1\n",
       "4           5  0         83          1\n",
       "..        ... ..        ...        ...\n",
       "796       994  0        652          1\n",
       "797       995  0        652          1\n",
       "798       996  0        778          1\n",
       "799       997  0        579          1\n",
       "800       998  0        539          1\n",
       "\n",
       "[801 rows x 4 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Raw Text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "url_pattern = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
    "username_pattern = r\"@[^\\s]+\"\n",
    "hashtag_pattern = r\"\\B#\\w\\w+\"\n",
    "token_pattern = r\"\\b[A-Za-z][A-Za-z]+\\b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of preprocessing tweet\n",
    "def preprocess_tweet(tweet, \n",
    "                     url_pattern=url_pattern, username_pattern=username_pattern, \n",
    "                     hashtag_pattern=hashtag_pattern, token_pattern=token_pattern, \n",
    "                     remove_url=True, remove_username=True, remove_hashtag=True,\n",
    "                     stopwords=stopwords, with_stopwordsrm=True, with_stemming=True):\n",
    "    \n",
    "    # remove content after '—'\n",
    "    tweet = tweet.split('—')[0]\n",
    "    \n",
    "    # remove url\n",
    "    if remove_url == True:\n",
    "        tweet = re.sub(url_pattern, \"\", tweet)\n",
    "        \n",
    "    # remove @username \n",
    "    if remove_username == True:\n",
    "        tweet = re.sub(username_pattern, \"\", tweet)\n",
    "        \n",
    "    # remove #hashtag\n",
    "    if remove_hashtag == True:\n",
    "        tweet = re.sub(hashtag_pattern, \"\", tweet)\n",
    "    \n",
    "    # lower case \n",
    "    tweet_lower = tweet.lower()\n",
    "    \n",
    "    # tokenization \n",
    "    words = re.findall(token_pattern, tweet_lower)\n",
    "    \n",
    "    # stopwords removal\n",
    "    if with_stopwordsrm == True:\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "    # stemming \n",
    "    if with_stemming == True:\n",
    "        ps = PorterStemmer() \n",
    "        words = [ps.stem(word) for word in words]\n",
    "        \n",
    "    tweet_processed = \" \".join(words)\n",
    "    \n",
    "    return tweet_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict tweets_tr: tweet_id -> tweet_content\n",
    "tweets_tr_prep = {}\n",
    "for tweet_id in tweets_tr.index:\n",
    "    tweets_tr_prep[tweet_id] = preprocess_tweet(tweets_tr.loc[tweet_id, 'tweet_content'])\n",
    "    \n",
    "\n",
    "# dict tweets_dev: tweet_id -> tweet_content\n",
    "tweets_dev_prep = {}\n",
    "for tweet_id in tweets_dev.index:\n",
    "    tweets_dev_prep[tweet_id] = preprocess_tweet(tweets_dev.loc[tweet_id, 'tweet_content'])\n",
    "\n",
    "start_time2 = time.time()\n",
    "# dict tweets_te: tweet_id -> tweet_content\n",
    "tweets_te_prep = {}\n",
    "for tweet_id in tweets_te.index:\n",
    "    tweets_te_prep[tweet_id] = preprocess_tweet(tweets_te.loc[tweet_id, 'tweet_content'])\n",
    "execution_time_list.append(time.time() - start_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of preprocessing vclaim\n",
    "def preprocess_text(text, token_pattern=token_pattern, stopwords=stopwords, \n",
    "                      with_stopwordsrm=True, with_stemming=True):\n",
    "    # lower case \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # tokenization \n",
    "    words = re.findall(token_pattern, text_lower)\n",
    "    \n",
    "    # stopwords removal\n",
    "    if with_stopwordsrm == True:\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        \n",
    "    # stemming \n",
    "    if with_stemming == True:\n",
    "        ps = PorterStemmer() \n",
    "        words = [ps.stem(word) for word in words]\n",
    "        \n",
    "    text_processed = \" \".join(words)\n",
    "    \n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict vclaim_prep: vlciam_id -> [vlciam_content, vclaim_title]\n",
    "vclaims_prep = {}\n",
    "for vclaim_id in vclaims.index:\n",
    "    vclaims_prep[vclaim_id] = []\n",
    "    vclaims_prep[vclaim_id].append(preprocess_text(vclaims.loc[vclaim_id, 'vclaim']))\n",
    "    vclaims_prep[vclaim_id].append(preprocess_text(vclaims.loc[vclaim_id, 'title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict vclaim_prep: vlciam_id -> [vlciam_content, vclaim_title]\n",
    "#test vclaims\n",
    "vclaims_test_prep = {}\n",
    "for vclaim_test_id in vclaims_test.index:\n",
    "    vclaims_test_prep[vclaim_test_id] = []\n",
    "    vclaims_test_prep[vclaim_test_id].append(preprocess_text(vclaims_test.loc[vclaim_test_id, 'vclaim']))\n",
    "    vclaims_test_prep[vclaim_test_id].append(preprocess_text(vclaims_test.loc[vclaim_test_id, 'title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Cosine Similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function of computing consine similarity \n",
    "def compute_cs(tweets, vclaims):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vclaims_tfidf = vectorizer.fit_transform(vclaims)\n",
    "    \n",
    "    cosine_sims = {}\n",
    "    for (tweet_id, tweet_content) in tweets.items():\n",
    "        tweet_tfidf = vectorizer.transform([tweet_content])\n",
    "        cs = cosine_similarity(tweet_tfidf, vclaims_tfidf).flatten()\n",
    "        cosine_sims[tweet_id] = cs\n",
    "    \n",
    "    return cosine_sims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing Cosine Similarities for train, dev and test set\n",
    "vclaims_contents = [vclaim[0] for vclaim in vclaims_prep.values()]\n",
    "vclaims_titles = [vclaim[1] for vclaim in vclaims_prep.values()]\n",
    "\n",
    "vclaims_test_contents = [vclaim[0] for vclaim in vclaims_test_prep.values()]\n",
    "vclaims_test_titles = [vclaim[1] for vclaim in vclaims_test_prep.values()]\n",
    "\n",
    "cs_tvc_tr = compute_cs(tweets_tr_prep, vclaims_contents)\n",
    "cs_tvt_tr = compute_cs(tweets_tr_prep, vclaims_titles)\n",
    "\n",
    "cs_tvc_dev = compute_cs(tweets_dev_prep, vclaims_contents)\n",
    "cs_tvt_dev = compute_cs(tweets_dev_prep, vclaims_titles)\n",
    "\n",
    "start_time3 = time.time()\n",
    "cs_tvc_te = compute_cs(tweets_te_prep, vclaims_test_contents)\n",
    "cs_tvt_te = compute_cs(tweets_te_prep, vclaims_test_titles)\n",
    "execution_time_list.append(time.time() - start_time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs_tvc_tr = pd.DataFrame.from_dict(cs_tvc_tr, orient='index')\n",
    "df_cs_tvt_tr = pd.DataFrame.from_dict(cs_tvt_tr, orient='index')\n",
    "\n",
    "df_cs_tvc_dev = pd.DataFrame.from_dict(cs_tvc_dev, orient='index')\n",
    "df_cs_tvt_dev = pd.DataFrame.from_dict(cs_tvt_dev, orient='index')\n",
    "\n",
    "start_time4 = time.time()\n",
    "df_cs_tvc_te = pd.DataFrame.from_dict(cs_tvc_te, orient='index')\n",
    "df_cs_tvt_te = pd.DataFrame.from_dict(cs_tvt_te, orient='index')\n",
    "execution_time_list.append(time.time() - start_time4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing BM25 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of computing BM25 score\n",
    "def compute_bm25(tokenized_tweets, tokenized_vclaims):\n",
    "    bm25kapi = BM25Okapi(tokenized_vclaims)\n",
    "    \n",
    "    bm25s = {}\n",
    "    for (tweet_id, tweet_content) in tokenized_tweets.items():\n",
    "        bm25s[tweet_id] = bm25kapi.get_scores(tweet_content)\n",
    "        \n",
    "    return bm25s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing pre-processed text\n",
    "tokenized_vclaims_contents = [vclaim[0].split(\" \") for vclaim in vclaims_prep.values()]\n",
    "tokenized_vclaims_titles = [vclaim[1].split(\" \") for vclaim in vclaims_prep.values()]\n",
    "\n",
    "tokenized_vclaims_test_contents = [vclaim[0].split(\" \") for vclaim in vclaims_test_prep.values()]\n",
    "tokenized_vclaims_test_titles = [vclaim[1].split(\" \") for vclaim in vclaims_test_prep.values()]\n",
    "\n",
    "tokenized_tweets_tr = {}\n",
    "for (tweet_id, tweet_content) in tweets_tr_prep.items():\n",
    "    tokenized_tweets_tr[tweet_id] = tweet_content.split(\" \")\n",
    "    \n",
    "tokenized_tweets_dev = {}\n",
    "for (tweet_id, tweet_content) in tweets_dev_prep.items():\n",
    "    tokenized_tweets_dev[tweet_id] = tweet_content.split(\" \")\n",
    "\n",
    "start_time5 = time.time()    \n",
    "tokenized_tweets_te = {}\n",
    "for (tweet_id, tweet_content) in tweets_te_prep.items():\n",
    "    tokenized_tweets_te[tweet_id] = tweet_content.split(\" \")\n",
    "execution_time_list.append(time.time() - start_time5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing BM25 Scores for train and test set\n",
    "bm25_tvc_tr = compute_bm25(tokenized_tweets_tr, tokenized_vclaims_contents)\n",
    "bm25_tvt_tr = compute_bm25(tokenized_tweets_tr, tokenized_vclaims_titles)\n",
    "\n",
    "bm25_tvc_dev = compute_bm25(tokenized_tweets_dev, tokenized_vclaims_contents)\n",
    "bm25_tvt_dev = compute_bm25(tokenized_tweets_dev, tokenized_vclaims_titles)\n",
    "\n",
    "start_time6 = time.time()\n",
    "bm25_tvc_te = compute_bm25(tokenized_tweets_te, tokenized_vclaims_test_contents)\n",
    "bm25_tvt_te = compute_bm25(tokenized_tweets_te, tokenized_vclaims_test_titles)\n",
    "execution_time_list.append(time.time() - start_time6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bm25_tvc_tr = pd.DataFrame.from_dict(bm25_tvc_tr, orient='index')\n",
    "df_bm25_tvt_tr = pd.DataFrame.from_dict(bm25_tvt_tr, orient='index')\n",
    "\n",
    "df_bm25_tvc_dev = pd.DataFrame.from_dict(bm25_tvc_dev, orient='index')\n",
    "df_bm25_tvt_dev = pd.DataFrame.from_dict(bm25_tvt_dev, orient='index')\n",
    "\n",
    "start_time7 = time.time()\n",
    "df_bm25_tvc_te = pd.DataFrame.from_dict(bm25_tvc_te, orient='index')\n",
    "df_bm25_tvt_te = pd.DataFrame.from_dict(bm25_tvt_te, orient='index')\n",
    "execution_time_list.append(time.time() - start_time7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing dataset with 4 features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>vid</th>\n",
       "      <th>cs_tvc</th>\n",
       "      <th>cs_tvt</th>\n",
       "      <th>bm25_tvc</th>\n",
       "      <th>bm25_tvt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033950</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>4.796907</td>\n",
       "      <td>4.506260</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999995</th>\n",
       "      <td>998</td>\n",
       "      <td>10370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999996</th>\n",
       "      <td>998</td>\n",
       "      <td>10371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999997</th>\n",
       "      <td>998</td>\n",
       "      <td>10372</td>\n",
       "      <td>0.092393</td>\n",
       "      <td>0.167614</td>\n",
       "      <td>5.400515</td>\n",
       "      <td>6.550036</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999998</th>\n",
       "      <td>998</td>\n",
       "      <td>10373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999999</th>\n",
       "      <td>998</td>\n",
       "      <td>10374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tid    vid    cs_tvc    cs_tvt  bm25_tvc  bm25_tvt  label\n",
       "0          1      0  0.000000  0.000000  0.000000  0.000000    0.0\n",
       "1          1      1  0.000000  0.000000  0.000000  0.000000    0.0\n",
       "2          1      2  0.033950  0.044334  4.796907  4.506260    0.0\n",
       "3          1      3  0.000000  0.000000  0.000000  0.000000    0.0\n",
       "4          1      4  0.000000  0.000000  0.000000  0.000000    0.0\n",
       "...      ...    ...       ...       ...       ...       ...    ...\n",
       "7999995  998  10370  0.000000  0.000000  0.000000  0.000000    0.0\n",
       "7999996  998  10371  0.000000  0.000000  0.000000  0.000000    0.0\n",
       "7999997  998  10372  0.092393  0.167614  5.400515  6.550036    0.0\n",
       "7999998  998  10373  0.000000  0.000000  0.000000  0.000000    0.0\n",
       "7999999  998  10374  0.000000  0.000000  0.000000  0.000000    0.0\n",
       "\n",
       "[8000000 rows x 7 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=vclaims.shape[0]\n",
    "data_tr_tids = []\n",
    "for tweet_id in tweets_tr_prep.keys():\n",
    "    for i in range(n):\n",
    "        data_tr_tids.append(tweet_id)\n",
    "        \n",
    "# data_tr_tids = []\n",
    "# for tweet_id in tweets_tr_prep.keys():\n",
    "#     data_tr_tids.extend((np.ones(vclaims.shape[0]) * tweet_id).tolist())\n",
    "#print(list(vclaims_prep.keys()))    \n",
    "data_tr_vids = []\n",
    "for i in range(tweets_tr.shape[0]):\n",
    "    data_tr_vids.extend(list(vclaims_prep.keys()))\n",
    "    \n",
    "data_tr_labels = []\n",
    "for tweet_id in tweets_tr_prep.keys():\n",
    "    labels = np.zeros(vclaims.shape[0])\n",
    "    #print(len(labels))\n",
    "    #print(qrels_tr['tweet_id'].values)\n",
    "    if tweet_id in qrels_tr['tweet_id'].values:\n",
    "        #print(qrels_tr[qrels_tr['tweet_id'] == tweet_id].values)\n",
    "        for index in qrels_tr[qrels_tr['tweet_id'] == tweet_id]['vclaim_id'].values:\n",
    "            for claim_index, claim_value in enumerate(list(vclaims_prep.keys())):\n",
    "                if index == claim_value:\n",
    "                    labels[claim_index] = 1\n",
    "                    \n",
    "                    \n",
    "                                \n",
    "    data_tr_labels.extend(labels)\n",
    "    \n",
    "data_tr = pd.DataFrame(columns=['tid', 'vid', 'cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt', 'label'])\n",
    "data_tr['tid'] = data_tr_tids\n",
    "data_tr['vid'] = data_tr_vids\n",
    "data_tr['cs_tvc'] = df_cs_tvc_tr.values.flatten()\n",
    "data_tr['cs_tvt'] = df_cs_tvt_tr.values.flatten()\n",
    "data_tr['bm25_tvc'] = df_bm25_tvc_tr.values.flatten()\n",
    "data_tr['bm25_tvt'] = df_bm25_tvt_tr.values.flatten()\n",
    "data_tr['label'] = data_tr_labels\n",
    "data_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>vid</th>\n",
       "      <th>cs_tvc</th>\n",
       "      <th>cs_tvt</th>\n",
       "      <th>bm25_tvc</th>\n",
       "      <th>bm25_tvt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969995</th>\n",
       "      <td>986</td>\n",
       "      <td>10370</td>\n",
       "      <td>0.029491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.19514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969996</th>\n",
       "      <td>986</td>\n",
       "      <td>10371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969997</th>\n",
       "      <td>986</td>\n",
       "      <td>10372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969998</th>\n",
       "      <td>986</td>\n",
       "      <td>10373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969999</th>\n",
       "      <td>986</td>\n",
       "      <td>10374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1970000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tid    vid    cs_tvc  cs_tvt  bm25_tvc  bm25_tvt  label\n",
       "0          0      0  0.000000     0.0   0.00000       0.0    0.0\n",
       "1          0      1  0.000000     0.0   0.00000       0.0    0.0\n",
       "2          0      2  0.000000     0.0   0.00000       0.0    0.0\n",
       "3          0      3  0.000000     0.0   0.00000       0.0    0.0\n",
       "4          0      4  0.000000     0.0   0.00000       0.0    0.0\n",
       "...      ...    ...       ...     ...       ...       ...    ...\n",
       "1969995  986  10370  0.029491     0.0   3.19514       0.0    0.0\n",
       "1969996  986  10371  0.000000     0.0   0.00000       0.0    0.0\n",
       "1969997  986  10372  0.000000     0.0   0.00000       0.0    0.0\n",
       "1969998  986  10373  0.000000     0.0   0.00000       0.0    0.0\n",
       "1969999  986  10374  0.000000     0.0   0.00000       0.0    0.0\n",
       "\n",
       "[1970000 rows x 7 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n=vclaims.shape[0]\n",
    "data_dev_tids = []\n",
    "for tweet_id in tweets_dev_prep.keys():\n",
    "    for i in range(n):\n",
    "        data_dev_tids.append(tweet_id)\n",
    "\n",
    "#data_dev_tids = []\n",
    "#for tweet_id in tweets_dev_prep.keys():\n",
    "#    #print(tweet_id)\n",
    "#    data_dev_tids.extend((np.ones(vclaims.shape[0]) * tweet_id).tolist())\n",
    "    \n",
    "data_dev_vids = []\n",
    "for i in range(tweets_dev.shape[0]):\n",
    "    data_dev_vids.extend(list(vclaims_prep.keys()))\n",
    "    \n",
    "data_dev_labels = []\n",
    "for tweet_id in tweets_dev_prep.keys():\n",
    "    labels = np.zeros(vclaims.shape[0])\n",
    "    if tweet_id in qrels_dev['tweet_id'].values:\n",
    "        for index in qrels_dev[qrels_dev['tweet_id'] == tweet_id]['vclaim_id'].values:\n",
    "            for claim_index, claim_value in enumerate(list(vclaims_prep.keys())):\n",
    "                if index == claim_value:\n",
    "                    labels[claim_index] = 1\n",
    "    data_dev_labels.extend(labels)\n",
    "    \n",
    "data_dev = pd.DataFrame(columns=['tid', 'vid', 'cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt', 'label'])\n",
    "data_dev['tid'] = data_dev_tids\n",
    "data_dev['vid'] = data_dev_vids\n",
    "data_dev['cs_tvc'] = df_cs_tvc_dev.values.flatten()\n",
    "data_dev['cs_tvt'] = df_cs_tvt_dev.values.flatten()\n",
    "data_dev['bm25_tvc'] = df_bm25_tvc_dev.values.flatten()\n",
    "data_dev['bm25_tvt'] = df_bm25_tvt_dev.values.flatten()\n",
    "data_dev['label'] = data_dev_labels\n",
    "data_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>vid</th>\n",
       "      <th>cs_tvc</th>\n",
       "      <th>cs_tvt</th>\n",
       "      <th>bm25_tvc</th>\n",
       "      <th>bm25_tvt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>999</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999995</th>\n",
       "      <td>1198</td>\n",
       "      <td>10370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999996</th>\n",
       "      <td>1198</td>\n",
       "      <td>10371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999997</th>\n",
       "      <td>1198</td>\n",
       "      <td>10372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>1198</td>\n",
       "      <td>10373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999999</th>\n",
       "      <td>1198</td>\n",
       "      <td>10374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tid    vid  cs_tvc  cs_tvt  bm25_tvc  bm25_tvt label\n",
       "0         999      0     0.0     0.0       0.0       0.0   NaN\n",
       "1         999      1     0.0     0.0       0.0       0.0   NaN\n",
       "2         999      2     0.0     0.0       0.0       0.0   NaN\n",
       "3         999      3     0.0     0.0       0.0       0.0   NaN\n",
       "4         999      4     0.0     0.0       0.0       0.0   NaN\n",
       "...       ...    ...     ...     ...       ...       ...   ...\n",
       "1999995  1198  10370     0.0     0.0       0.0       0.0   NaN\n",
       "1999996  1198  10371     0.0     0.0       0.0       0.0   NaN\n",
       "1999997  1198  10372     0.0     0.0       0.0       0.0   NaN\n",
       "1999998  1198  10373     0.0     0.0       0.0       0.0   NaN\n",
       "1999999  1198  10374     0.0     0.0       0.0       0.0   NaN\n",
       "\n",
       "[2000000 rows x 7 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(vclaims.shape[0])\n",
    "start_time8 = time.time()\n",
    "n=vclaims_test.shape[0]\n",
    "#print(vclaims_test.shape[0])\n",
    "data_te_tids = []\n",
    "for tweet_value in tweets_te_prep.keys():\n",
    "    for i in range(n):\n",
    "        data_te_tids.append(tweet_value)\n",
    "\n",
    "#print(data_te_tids)        \n",
    "#data_te_tids.extend((np.ones(vclaims.shape[0]) * tweet_id).tolist())\n",
    "    \n",
    "data_te_vids = []\n",
    "for i in range(tweets_te.shape[0]):\n",
    "    data_te_vids.extend(list(vclaims_test_prep.keys()))\n",
    "    \n",
    "data_te = pd.DataFrame(columns=['tid', 'vid', 'cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt', 'label'])\n",
    "data_te['tid'] = data_te_tids\n",
    "data_te['vid'] = data_te_vids\n",
    "data_te['cs_tvc'] = df_cs_tvc_te.values.flatten()\n",
    "data_te['cs_tvt'] = df_cs_tvt_te.values.flatten()\n",
    "data_te['bm25_tvc'] = df_bm25_tvc_te.values.flatten()\n",
    "data_te['bm25_tvt'] = df_bm25_tvt_te.values.flatten()\n",
    "execution_time_list.append(time.time() - start_time8)\n",
    "data_te\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr = data_tr[['cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt']].values, data_tr['label'].values\n",
    "X_dev, y_dev = data_dev[['cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt']].values, data_dev['label'].values\n",
    "start_time9 = time.time()\n",
    "X_te = data_te[['cs_tvc', 'cs_tvt', 'bm25_tvc', 'bm25_tvt']].values\n",
    "execution_time_list.append(time.time() - start_time9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing class weights to handle data imbalance\n",
    "class_weight = {}\n",
    "for label in set(y_dev):\n",
    "    class_weight[label] = np.sum(y_dev == label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usama\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(C=0.1, random_state=0, class_weight=class_weight, max_iter=1000).fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generating result for dev data set\n",
    "#score_dev = np.sum(X_dev * clf.coef_, axis=1) + clf.intercept_\n",
    "\n",
    "#result_dev_score = pd.DataFrame(columns=['tid','vid', 'score'])\n",
    "#result_dev_score['tid'] = data_dev['tid']\n",
    "#result_dev_score['vid'] = data_dev['vid']\n",
    "#result_dev_score['score'] = score_dev\n",
    "\n",
    "#result_dev = pd.DataFrame(columns=['tweet_id', 'Q0', 'vclaim_id', 'rank', 'score', 'tag'])\n",
    "\n",
    "#tid = list(result_dev_score.groupby(by='tid').groups.keys())\n",
    "#for i in tid:\n",
    "#    idx = result_dev_score[result_dev_score['tid'] == i]['score'].idxmax()\n",
    "#    inf = result_dev_score.iloc[idx]\n",
    "#    result_dev = result_dev.append({'tweet_id':str(inf[0]), 'Q0':'Q0', 'vclaim_id':str(inf[1]), \n",
    "#                                    'rank':1, 'score':inf[2], 'tag': 'COVID-19'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_dev.to_csv('dev_set_results/golf_system_result_dev_1.csv', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.005002737045288086, 0.07403206825256348, 0.9867169857025146, 1.6071085929870605, 0.0010149478912353516, 7.268547773361206, 1.6135482788085938, 1.9235944747924805, 0.05650067329406738, 1.6026272773742676]\n"
     ]
    }
   ],
   "source": [
    "# generating result for test data set\n",
    "start_time10 = time.time()\n",
    "score_te = np.sum(X_te * clf.coef_, axis=1) + clf.intercept_\n",
    "\n",
    "result_te_score = pd.DataFrame(columns=['tid','vid', 'score'])\n",
    "result_te_score['tid'] = data_te['tid']\n",
    "result_te_score['vid'] = data_te['vid']\n",
    "result_te_score['score'] = score_te\n",
    "result_te = pd.DataFrame(columns=['tweet_id', 'Q0', 'vclaim_id', 'rank', 'score', 'tag'])\n",
    "\n",
    "tid = list(result_te_score.groupby(by='tid').groups.keys())\n",
    "for i in tid:\n",
    "    idx = result_te_score[result_te_score['tid'] == i]['score'].idxmax()\n",
    "    inf = result_te_score.iloc[idx]\n",
    "    result_te = result_te.append({'tweet_id':str(inf[0]), 'Q0':'Q0', 'vclaim_id':str(inf[1]), \n",
    "                                    'rank':1, 'score':inf[2], 'tag': 'COVID-19'}, ignore_index=True)\n",
    "execution_time_list.append(time.time() - start_time10)  \n",
    "print(execution_time_list)\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.138693809509277"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(execution_time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.6747047901153564, 3.5895118713378906, 3.4903786182403564\n",
    "#10.910948276519775, 11.244364023208618, 11.463943243026733\n",
    "#14.942622900009155, 15.129878997802734, 15.138693809509277\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>Q0</th>\n",
       "      <th>vclaim_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999.0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>6094.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.958960</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>6094.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.974329</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.980473</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002.0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>8005.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.966464</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003.0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>8005.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.952421</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1194.0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>4693.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.982003</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1195.0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>10039.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.977978</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1196.0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>8855.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.984181</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1197.0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>5553.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.925080</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1198.0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>9807.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.975069</td>\n",
       "      <td>COVID-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id  Q0 vclaim_id rank     score       tag\n",
       "0      999.0  Q0    6094.0    1 -0.958960  COVID-19\n",
       "1     1000.0  Q0    6094.0    1 -0.974329  COVID-19\n",
       "2     1001.0  Q0     582.0    1 -0.980473  COVID-19\n",
       "3     1002.0  Q0    8005.0    1 -0.966464  COVID-19\n",
       "4     1003.0  Q0    8005.0    1 -0.952421  COVID-19\n",
       "..       ...  ..       ...  ...       ...       ...\n",
       "195   1194.0  Q0    4693.0    1 -0.982003  COVID-19\n",
       "196   1195.0  Q0   10039.0    1 -0.977978  COVID-19\n",
       "197   1196.0  Q0    8855.0    1 -0.984181  COVID-19\n",
       "198   1197.0  Q0    5553.0    1 -0.925080  COVID-19\n",
       "199   1198.0  Q0    9807.0    1 -0.975069  COVID-19\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_te.to_csv('test_set_results/golf_system_result_te_1.csv', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python lib/evaluate.py -s test_set_results/golf_system_result_te_1.csv -g data/data/tweet-vclaim-pairs.qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
